{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPO-v0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moodlep/rl-playground/blob/main/ppo/colab_notebooks/PPO_v0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations"
      ],
      "metadata": {
        "id": "v6b7vGWAq1V3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJsXm7tEqPlR",
        "outputId": "4f880977-710c-4703-f5cf-f4e5c21ad54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 112 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 122 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 174 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 194 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 225 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 245 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 296 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 317 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 337 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 348 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 368 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 389 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 399 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 409 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 440 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 448 kB 9.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install box2d-py\n",
        "!pip3 install gym[Box_2D]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKKl_RhVVV0k",
        "outputId": "c17c412a-525b-440c-dc12-ce53b80b3614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-1.3.0-py3-none-any.whl (174 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 40 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 61 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 71 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 81 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 92 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 102 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 112 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 122 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 133 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 143 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 153 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 163 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 174 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.10.0+cu111)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.1.5)\n",
            "Requirement already satisfied: gym<0.20,>=0.17 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (0.17.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.20,>=0.17->stable-baselines3) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->stable-baselines3) (3.10.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3) (2018.9)\n",
            "Installing collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deq0in1i1iM7"
      },
      "source": [
        "import os\n",
        "import Box2D\n",
        "import pyglet\n",
        "import imageio\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "954_wRxQtHoe"
      },
      "source": [
        "import gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "import multiprocessing\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8sWOcdBXz0OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Env"
      ],
      "metadata": {
        "id": "vP7-384nq68Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_id = \"LunarLanderContinuous-v2\"\n",
        "env = gym.make(env_id)\n"
      ],
      "metadata": {
        "id": "pJLrFY2yqygl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaCGLNAVzc5f",
        "outputId": "fbe286d9-a2f2-4a03-b5b8-78dd2a744c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00450096,  1.4039963 ,  0.4558782 , -0.30773082, -0.00520864,\n",
              "       -0.10326321,  0.        ,  0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_space.shape, env.observation_space.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5Jx9DjLziVh",
        "outputId": "8d6538c9-4da6-4133-e54b-f2e2db9b7cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for episode in range(1): \n",
        "    observation = env.reset()\n",
        "    for step in range(1):\n",
        "        action = env.action_space.sample()  # or given a custom model, action = policy(observation)\n",
        "        observation, reward, done, info = env.step(action)\n",
        "        print(observation, reward, done, info, action)"
      ],
      "metadata": {
        "id": "w5VZUesWzlEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338bacdd-9f6b-434c-86be-502ce5310ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.01517162  1.3966358   0.76332283 -0.3303236  -0.01610824 -0.1458994\n",
            "  0.          0.        ] -0.28190276977425355 False {} [-0.5224455 -0.6211104]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ActorCritic Model"
      ],
      "metadata": {
        "id": "gK8QXZh40b8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9bs5HckwAY2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ActorCritic(nn.Module):\n",
        "\n",
        "  def __init__(self, state_dim, action_dim, std_init):\n",
        "    super(ActorCritic,self).__init__()\n",
        "\n",
        "    # TBD switch to variable std\n",
        "\n",
        "    self.action_dim = action_dim\n",
        "    self.state_dim = state_dim\n",
        "    self.critic = nn.Sequential(\n",
        "        nn.Linear(self.state_dim, 64),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(64, 64),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(64, 1)\n",
        "    )\n",
        "\n",
        "    self.actor = nn.Sequential(\n",
        "        nn.Linear(self.state_dim, 64),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(64, 64),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(64, self.action_dim),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "    # covariance for Multivariate Normal policy\n",
        "    self.action_vars = torch.full((self.action_dim,), std_init * std_init)\n",
        "    self.cov_mat = torch.diag(self.action_vars).unsqueeze(dim=0)  # do we need the unsqueeze? \n",
        "\n",
        "  def forward(self, input):\n",
        "    values = self.critic(input)\n",
        "    logits = self.actor(input)\n",
        "    return values, logits\n",
        "\n",
        "  def get_action(self, state, action=None):\n",
        "    means = self.actor(state)\n",
        "    policy = torch.distributions.MultivariateNormal(means, self.cov_mat)\n",
        "    if action==None:\n",
        "      action = policy.sample()\n",
        "    return action,policy.log_prob(action)\n",
        "    \n",
        "  def get_value(self,state):\n",
        "    return self.critic(state)\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "W9PY6lVq0e8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ac = ActorCritic(env.observation_space.shape[0], env.action_space.shape[0], 0.05)"
      ],
      "metadata": {
        "id": "DnwAkRawFWXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "states = torch.rand"
      ],
      "metadata": {
        "id": "jQ7OHrqFTgQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pi = ac.get_action(torch.tensor([observation, observation]))\n",
        "pi[0].shape, pi"
      ],
      "metadata": {
        "id": "nKyi3OVFG3u6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "800a42f7-d895-468d-decd-59bb4417cce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 2]), (tensor([[ 0.2333,  0.0467],\n",
              "          [ 0.0868, -0.0096]]),\n",
              "  tensor([2.4380, 2.4004], grad_fn=<SubBackward0>)))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Envs"
      ],
      "metadata": {
        "id": "FWJeHwb1WEbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_env(env_id: str, rank: int, seed: int = 0):\n",
        "  def _init():\n",
        "    env = gym.make(env_id)\n",
        "    env.seed(seed + rank)\n",
        "    return env\n",
        "  torch.manual_seed(seed)\n",
        "  return _init\n",
        "\n",
        "num_cpu = 4\n",
        "env_p = SubprocVecEnv([make_env(env_id, i) for i in range(num_cpu)])\n"
      ],
      "metadata": {
        "id": "u8B6zMC4WuvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs = torch.tensor(env_p.reset())\n",
        "obs"
      ],
      "metadata": {
        "id": "_MyWS3NnjdbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3deea61f-7d83-4902-b4aa-c800094999b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-5.9156e-04,  1.4135e+00, -5.9936e-02,  1.1277e-01,  6.9229e-04,\n",
              "          1.3576e-02,  0.0000e+00,  0.0000e+00],\n",
              "        [-5.2567e-03,  1.3989e+00, -5.3248e-01, -5.3348e-01,  6.0981e-03,\n",
              "          1.2061e-01,  0.0000e+00,  0.0000e+00],\n",
              "        [-4.0088e-03,  1.4072e+00, -4.0605e-01, -1.6675e-01,  4.6519e-03,\n",
              "          9.1977e-02,  0.0000e+00,  0.0000e+00],\n",
              "        [-7.2308e-03,  1.4090e+00, -7.3242e-01, -8.7516e-02,  8.3855e-03,\n",
              "          1.6590e-01,  0.0000e+00,  0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PPO Class: "
      ],
      "metadata": {
        "id": "9cSJ3GJ9c6ZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* sort out seeds\n",
        "* to.device()\n"
      ],
      "metadata": {
        "id": "dD6i_9gEhuwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'std_init': 0.05,\n",
        "    'env_id': 'LunarLanderContinuous-v2',\n",
        "    'num_workers': 4,  # rank (seed) / envs / N\n",
        "    'num_epochs': 10, # K number of \n",
        "    'num_iterations': 10, # number of times we collect a dataset \n",
        "    'max_timesteps': 500, # T\n",
        "    'epsilon': 0.2,  # clipping radius\n",
        "    'gamma' : 0.99,\n",
        "    'minibatch_size' : 64,\n",
        "    'num_minibatches': 10 # need to decide how to mini-batch\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "RPAQJUMXbPzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PPO:\n",
        "  def __init__(self, config):\n",
        "\n",
        "    self.config = config\n",
        "    # self.num_cpus = multiprocessing.cpu_count()\n",
        "\n",
        "    self.envs = SubprocVecEnv([make_env(config['env_id'], i) for i in range(self.config['num_workers'])])\n",
        "\n",
        "    self.action_dim = self.envs.action_space.shape[0]\n",
        "    self.state_dim = self.envs.observation_space.shape[0]\n",
        "\n",
        "    self.model = ActorCritic(self.state_dim, self.action_dim, config['std_init'])\n",
        "\n",
        "    self.optimizer = torch.optim.Adam(self.model.parameters())\n",
        "    self.summary = SummaryWriter(log_dir='logs')\n",
        "\n",
        "  def create_rollout(self):\n",
        "\n",
        "    pass\n",
        "\n",
        "  def train(self): \n",
        "\n",
        "    # 10 Jan 2022: enable anomaly detection to find the operation that failed to compute its gradient\n",
        "    # torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "    # num_iterations = Number of updates: \n",
        "    for it in range(self.config['num_iterations']):\n",
        "      print('collect big batch - iteration number ', str(it))\n",
        "    \n",
        "      obs_batch = torch.zeros((self.config['max_timesteps'], self.config['num_workers'],  self.envs.observation_space.shape[0]))\n",
        "      action_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], self.envs.action_space.shape[0]))\n",
        "      reward_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1))\n",
        "      done_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1))\n",
        "      next_obs_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], self.envs.observation_space.shape[0]))\n",
        "      ratio_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1))\n",
        "      log_prob_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1))\n",
        "      advantage_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1))\n",
        "      returns_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1))\n",
        "      values_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'],1))   # can we remove the 1?\n",
        "      obs = self.envs.reset()\n",
        "\n",
        "      # capture NT rollouts \n",
        "      for t in range(self.config['max_timesteps']):\n",
        "        # print('rollout timestep: ', str(t), ' - get action')\n",
        "        with torch.no_grad():\n",
        "          actions,log_probs = self.model.get_action(torch.tensor(obs))\n",
        "\n",
        "        # print('rollout timestep: ', str(t), 'env step - async and wait')\n",
        "\n",
        "        self.envs.step_async(actions.numpy())\n",
        "        next_obs, rewards, dones, infos = self.envs.step_wait()\n",
        "        \n",
        "        # print('rollout timestep: ', str(t), 'gather batches: obs, action, reward, etc ', obs.shape, actions.shape, torch.tensor(rewards).shape)\n",
        "\n",
        "        obs_batch[t] = torch.tensor(obs)\n",
        "        action_batch[t] = torch.tensor(actions)\n",
        "        reward_batch[t] = torch.tensor(rewards.reshape(-1,1))\n",
        "        done_batch[t] = torch.tensor(dones.reshape(-1,1))\n",
        "        next_obs_batch[t] = torch.tensor(next_obs)\n",
        "        log_prob_batch[t] = log_probs.reshape(-1,1)\n",
        "        values_batch[t] = self.model.get_value(torch.tensor(obs)).reshape(-1,1)\n",
        "\n",
        "        obs = next_obs\n",
        "      \n",
        "      with torch.no_grad():\n",
        "        # print('returns to go - final step')\n",
        "        # Calculate returns to go - final step: \n",
        "        returns_batch[self.config['max_timesteps']-1] = torch.where(done_batch[self.config['max_timesteps']-1]==0,\n",
        "                                                                    reward_batch[self.config['max_timesteps']-1] + self.config['gamma']*self.model.get_value(next_obs_batch[self.config['max_timesteps']-1]).detach()\n",
        "                                                                    ,torch.tensor(0.0))  # torch.no_grad?\n",
        "\n",
        "        # print('returns to go and advantage calc')\n",
        "        # Calculate Advantage: \n",
        "        for t in range(self.config['max_timesteps']-2, -1, -1):\n",
        "          returns_batch[t] = torch.where(done_batch[t]==0, returns_batch[t+1]*self.config['gamma'] + reward_batch[t],torch.tensor(0.0))\n",
        "          advantage_batch[t] = returns_batch[t] - self.model.get_value(obs_batch[t])  # torch.no_grad? No - need grads!\n",
        "\n",
        "        # Reverse the whole batch?? \n",
        "        returns_batch = torch.flip(returns_batch,dims=[0])\n",
        "\n",
        "      # Optimization in k epochs:\n",
        "      for k in range(self.config['num_epochs']):\n",
        "        # Create some mini-batches and update TODO ****\n",
        "\n",
        "          # print('opt', flush=True)\n",
        "          obs_batch  = obs_batch.reshape(-1,self.envs.observation_space.shape[0])\n",
        "          action_batch = action_batch.reshape(-1, self.envs.action_space.shape[0])\n",
        "          reward_batch = reward_batch.reshape(-1,1)\n",
        "          done_batch = done_batch.reshape(-1,1)\n",
        "          next_obs_batch = next_obs_batch.reshape(-1,self.envs.observation_space.shape[0])\n",
        "          ratio_batch = ratio_batch.reshape(-1,1)\n",
        "          advantage_batch = advantage_batch.reshape(-1,1)\n",
        "          returns_batch = returns_batch.reshape(-1,1)\n",
        "          log_prob_batch = log_prob_batch.reshape(-1,1)\n",
        "          values_batch = values_batch.reshape(-1, 1).detach()\n",
        "          # print('opt2', flush=True)\n",
        "\n",
        "          for nmb in range(self.config['num_minibatches']):\n",
        "            # sample a mini-batch  - TODO - needs loop\n",
        "            sample = torch.randint(0,self.config['num_workers'] * self.config['max_timesteps'],(64,))  # is this the right way to train the epochs? whole epochs maybe??\n",
        "\n",
        "            _,new_log_probs = self.model.get_action(obs_batch[sample],action_batch[sample])   \n",
        "            ratio = torch.exp(new_log_probs - log_prob_batch[sample]) \n",
        "            # print('opt3', flush=True)\n",
        "            \n",
        "            # print(advantage_batch[sample].requires_grad)  # showing up as False... \n",
        "            objective = ratio*advantage_batch[sample].detach()\n",
        "            clipped_obj = torch.clamp(ratio,1-self.config['epsilon'],1+self.config['epsilon'])*advantage_batch[sample].detach()\n",
        "            value_loss = (returns_batch[sample]-values_batch[sample])**2 \n",
        "            loss = torch.mean(torch.min(objective,clipped_obj) - value_loss)  # swopped sign\n",
        "            # loss = torch.mean(torch.min(objective,clipped_obj) - advantage_batch[sample]**2)  # swopped sign\n",
        "            print(\"mini-batch \", str(nmb), \" loss is: \", loss.detach(), flush=True)\n",
        "            self.summary.add_scalar(\"loss\", loss.item(), nmb)  # need to calc global/epoch step count\n",
        "            # print('opt4', flush=True)\n",
        "            \n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "      # self.summary.add_graph(self.model, obs[0])  # temp - please remove!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9zcwpKAWZHhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo = PPO(config)\n",
        "ppo.train()"
      ],
      "metadata": {
        "id": "f8AtfIs7r5Z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4db57ec-dba1-4d8b-b3d5-9299f52be51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collect big batch - iteration number  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mini-batch  0  loss is:  tensor(-746.0175)\n",
            "mini-batch  1  loss is:  tensor(-509.5120)\n",
            "mini-batch  2  loss is:  tensor(-723.3445)\n",
            "mini-batch  3  loss is:  tensor(-586.2155)\n",
            "mini-batch  4  loss is:  tensor(-598.7020)\n",
            "mini-batch  5  loss is:  tensor(-583.2792)\n",
            "mini-batch  6  loss is:  tensor(-649.8322)\n",
            "mini-batch  7  loss is:  tensor(-685.8222)\n",
            "mini-batch  8  loss is:  tensor(-576.3699)\n",
            "mini-batch  9  loss is:  tensor(-685.5485)\n",
            "mini-batch  0  loss is:  tensor(-679.0809)\n",
            "mini-batch  1  loss is:  tensor(-771.6079)\n",
            "mini-batch  2  loss is:  tensor(-525.7799)\n",
            "mini-batch  3  loss is:  tensor(-731.4330)\n",
            "mini-batch  4  loss is:  tensor(-694.0738)\n",
            "mini-batch  5  loss is:  tensor(-737.4572)\n",
            "mini-batch  6  loss is:  tensor(-535.1644)\n",
            "mini-batch  7  loss is:  tensor(-542.3280)\n",
            "mini-batch  8  loss is:  tensor(-618.5316)\n",
            "mini-batch  9  loss is:  tensor(-712.6564)\n",
            "mini-batch  0  loss is:  tensor(-640.3350)\n",
            "mini-batch  1  loss is:  tensor(-551.5248)\n",
            "mini-batch  2  loss is:  tensor(-539.7510)\n",
            "mini-batch  3  loss is:  tensor(-735.5040)\n",
            "mini-batch  4  loss is:  tensor(-735.3800)\n",
            "mini-batch  5  loss is:  tensor(-798.6270)\n",
            "mini-batch  6  loss is:  tensor(-752.3491)\n",
            "mini-batch  7  loss is:  tensor(-828.0135)\n",
            "mini-batch  8  loss is:  tensor(-680.1550)\n",
            "mini-batch  9  loss is:  tensor(-693.9135)\n",
            "mini-batch  0  loss is:  tensor(-569.5146)\n",
            "mini-batch  1  loss is:  tensor(-751.3044)\n",
            "mini-batch  2  loss is:  tensor(-589.2414)\n",
            "mini-batch  3  loss is:  tensor(-515.5756)\n",
            "mini-batch  4  loss is:  tensor(-603.4403)\n",
            "mini-batch  5  loss is:  tensor(-697.3102)\n",
            "mini-batch  6  loss is:  tensor(-846.4753)\n",
            "mini-batch  7  loss is:  tensor(-523.8181)\n",
            "mini-batch  8  loss is:  tensor(-670.0806)\n",
            "mini-batch  9  loss is:  tensor(-626.5033)\n",
            "mini-batch  0  loss is:  tensor(-550.5924)\n",
            "mini-batch  1  loss is:  tensor(-686.2808)\n",
            "mini-batch  2  loss is:  tensor(-542.8470)\n",
            "mini-batch  3  loss is:  tensor(-636.8729)\n",
            "mini-batch  4  loss is:  tensor(-490.5495)\n",
            "mini-batch  5  loss is:  tensor(-465.5592)\n",
            "mini-batch  6  loss is:  tensor(-677.2928)\n",
            "mini-batch  7  loss is:  tensor(-657.9265)\n",
            "mini-batch  8  loss is:  tensor(-628.5954)\n",
            "mini-batch  9  loss is:  tensor(-425.6568)\n",
            "mini-batch  0  loss is:  tensor(-454.5646)\n",
            "mini-batch  1  loss is:  tensor(-776.9299)\n",
            "mini-batch  2  loss is:  tensor(-599.5361)\n",
            "mini-batch  3  loss is:  tensor(-589.1656)\n",
            "mini-batch  4  loss is:  tensor(-789.4058)\n",
            "mini-batch  5  loss is:  tensor(-550.5879)\n",
            "mini-batch  6  loss is:  tensor(-596.8282)\n",
            "mini-batch  7  loss is:  tensor(-625.3936)\n",
            "mini-batch  8  loss is:  tensor(-507.3375)\n",
            "mini-batch  9  loss is:  tensor(-611.4740)\n",
            "mini-batch  0  loss is:  tensor(-639.8443)\n",
            "mini-batch  1  loss is:  tensor(-724.4708)\n",
            "mini-batch  2  loss is:  tensor(-463.5562)\n",
            "mini-batch  3  loss is:  tensor(-510.2658)\n",
            "mini-batch  4  loss is:  tensor(-707.9274)\n",
            "mini-batch  5  loss is:  tensor(-618.0726)\n",
            "mini-batch  6  loss is:  tensor(-867.4851)\n",
            "mini-batch  7  loss is:  tensor(-698.5137)\n",
            "mini-batch  8  loss is:  tensor(-622.3665)\n",
            "mini-batch  9  loss is:  tensor(-746.3452)\n",
            "mini-batch  0  loss is:  tensor(-530.1941)\n",
            "mini-batch  1  loss is:  tensor(-588.3321)\n",
            "mini-batch  2  loss is:  tensor(-527.2548)\n",
            "mini-batch  3  loss is:  tensor(-803.6600)\n",
            "mini-batch  4  loss is:  tensor(-592.9402)\n",
            "mini-batch  5  loss is:  tensor(-676.4612)\n",
            "mini-batch  6  loss is:  tensor(-609.4812)\n",
            "mini-batch  7  loss is:  tensor(-606.6880)\n",
            "mini-batch  8  loss is:  tensor(-657.0664)\n",
            "mini-batch  9  loss is:  tensor(-438.8348)\n",
            "mini-batch  0  loss is:  tensor(-397.3135)\n",
            "mini-batch  1  loss is:  tensor(-635.1932)\n",
            "mini-batch  2  loss is:  tensor(-444.3185)\n",
            "mini-batch  3  loss is:  tensor(-374.3032)\n",
            "mini-batch  4  loss is:  tensor(-612.0802)\n",
            "mini-batch  5  loss is:  tensor(-647.2271)\n",
            "mini-batch  6  loss is:  tensor(-524.7531)\n",
            "mini-batch  7  loss is:  tensor(-785.9471)\n",
            "mini-batch  8  loss is:  tensor(-437.3177)\n",
            "mini-batch  9  loss is:  tensor(-514.7787)\n",
            "mini-batch  0  loss is:  tensor(-774.9289)\n",
            "mini-batch  1  loss is:  tensor(-717.2864)\n",
            "mini-batch  2  loss is:  tensor(-699.2194)\n",
            "mini-batch  3  loss is:  tensor(-506.0833)\n",
            "mini-batch  4  loss is:  tensor(-582.9689)\n",
            "mini-batch  5  loss is:  tensor(-772.5430)\n",
            "mini-batch  6  loss is:  tensor(-681.6173)\n",
            "mini-batch  7  loss is:  tensor(-593.5364)\n",
            "mini-batch  8  loss is:  tensor(-496.4836)\n",
            "mini-batch  9  loss is:  tensor(-765.2894)\n",
            "collect big batch - iteration number  1\n",
            "mini-batch  0  loss is:  tensor(-704.9587)\n",
            "mini-batch  1  loss is:  tensor(-855.9964)\n",
            "mini-batch  2  loss is:  tensor(-910.3062)\n",
            "mini-batch  3  loss is:  tensor(-874.5547)\n",
            "mini-batch  4  loss is:  tensor(-1642.6642)\n",
            "mini-batch  5  loss is:  tensor(-793.7028)\n",
            "mini-batch  6  loss is:  tensor(-844.0713)\n",
            "mini-batch  7  loss is:  tensor(-1313.1311)\n",
            "mini-batch  8  loss is:  tensor(-1325.4106)\n",
            "mini-batch  9  loss is:  tensor(-1214.4338)\n",
            "mini-batch  0  loss is:  tensor(-1247.5714)\n",
            "mini-batch  1  loss is:  tensor(-1170.4185)\n",
            "mini-batch  2  loss is:  tensor(-958.2839)\n",
            "mini-batch  3  loss is:  tensor(-856.4001)\n",
            "mini-batch  4  loss is:  tensor(-1775.2207)\n",
            "mini-batch  5  loss is:  tensor(-1147.8173)\n",
            "mini-batch  6  loss is:  tensor(-1220.1532)\n",
            "mini-batch  7  loss is:  tensor(-870.3528)\n",
            "mini-batch  8  loss is:  tensor(-755.5308)\n",
            "mini-batch  9  loss is:  tensor(-740.5497)\n",
            "mini-batch  0  loss is:  tensor(-1032.0742)\n",
            "mini-batch  1  loss is:  tensor(-970.3239)\n",
            "mini-batch  2  loss is:  tensor(-1128.6979)\n",
            "mini-batch  3  loss is:  tensor(-699.2411)\n",
            "mini-batch  4  loss is:  tensor(-1199.2346)\n",
            "mini-batch  5  loss is:  tensor(-792.5191)\n",
            "mini-batch  6  loss is:  tensor(-830.3345)\n",
            "mini-batch  7  loss is:  tensor(-954.0802)\n",
            "mini-batch  8  loss is:  tensor(-809.8768)\n",
            "mini-batch  9  loss is:  tensor(-1097.7012)\n",
            "mini-batch  0  loss is:  tensor(-1240.2974)\n",
            "mini-batch  1  loss is:  tensor(-802.5706)\n",
            "mini-batch  2  loss is:  tensor(-1444.6196)\n",
            "mini-batch  3  loss is:  tensor(-929.0720)\n",
            "mini-batch  4  loss is:  tensor(-1135.8610)\n",
            "mini-batch  5  loss is:  tensor(-833.9897)\n",
            "mini-batch  6  loss is:  tensor(-940.6136)\n",
            "mini-batch  7  loss is:  tensor(-679.6973)\n",
            "mini-batch  8  loss is:  tensor(-1794.8129)\n",
            "mini-batch  9  loss is:  tensor(-951.2685)\n",
            "mini-batch  0  loss is:  tensor(-1095.8181)\n",
            "mini-batch  1  loss is:  tensor(-862.5665)\n",
            "mini-batch  2  loss is:  tensor(-998.4770)\n",
            "mini-batch  3  loss is:  tensor(-947.0148)\n",
            "mini-batch  4  loss is:  tensor(-665.4465)\n",
            "mini-batch  5  loss is:  tensor(-924.7534)\n",
            "mini-batch  6  loss is:  tensor(-959.5347)\n",
            "mini-batch  7  loss is:  tensor(-1046.6077)\n",
            "mini-batch  8  loss is:  tensor(-1101.4198)\n",
            "mini-batch  9  loss is:  tensor(-771.6787)\n",
            "mini-batch  0  loss is:  tensor(-911.1881)\n",
            "mini-batch  1  loss is:  tensor(-1119.2245)\n",
            "mini-batch  2  loss is:  tensor(-1444.2273)\n",
            "mini-batch  3  loss is:  tensor(-899.5936)\n",
            "mini-batch  4  loss is:  tensor(-1142.2239)\n",
            "mini-batch  5  loss is:  tensor(-1083.1200)\n",
            "mini-batch  6  loss is:  tensor(-708.2083)\n",
            "mini-batch  7  loss is:  tensor(-1120.0973)\n",
            "mini-batch  8  loss is:  tensor(-1112.3712)\n",
            "mini-batch  9  loss is:  tensor(-1340.4561)\n",
            "mini-batch  0  loss is:  tensor(-1149.7821)\n",
            "mini-batch  1  loss is:  tensor(-705.7661)\n",
            "mini-batch  2  loss is:  tensor(-1014.8759)\n",
            "mini-batch  3  loss is:  tensor(-1748.3904)\n",
            "mini-batch  4  loss is:  tensor(-517.3154)\n",
            "mini-batch  5  loss is:  tensor(-778.1787)\n",
            "mini-batch  6  loss is:  tensor(-1067.9976)\n",
            "mini-batch  7  loss is:  tensor(-1630.0750)\n",
            "mini-batch  8  loss is:  tensor(-846.2534)\n",
            "mini-batch  9  loss is:  tensor(-666.5233)\n",
            "mini-batch  0  loss is:  tensor(-1389.5634)\n",
            "mini-batch  1  loss is:  tensor(-729.0982)\n",
            "mini-batch  2  loss is:  tensor(-979.2272)\n",
            "mini-batch  3  loss is:  tensor(-1162.9374)\n",
            "mini-batch  4  loss is:  tensor(-1464.7028)\n",
            "mini-batch  5  loss is:  tensor(-876.2971)\n",
            "mini-batch  6  loss is:  tensor(-660.8504)\n",
            "mini-batch  7  loss is:  tensor(-1179.7329)\n",
            "mini-batch  8  loss is:  tensor(-850.4513)\n",
            "mini-batch  9  loss is:  tensor(-902.4379)\n",
            "mini-batch  0  loss is:  tensor(-1129.4946)\n",
            "mini-batch  1  loss is:  tensor(-937.4562)\n",
            "mini-batch  2  loss is:  tensor(-780.6178)\n",
            "mini-batch  3  loss is:  tensor(-836.5718)\n",
            "mini-batch  4  loss is:  tensor(-871.9348)\n",
            "mini-batch  5  loss is:  tensor(-1497.0757)\n",
            "mini-batch  6  loss is:  tensor(-1198.6591)\n",
            "mini-batch  7  loss is:  tensor(-1202.9827)\n",
            "mini-batch  8  loss is:  tensor(-822.3942)\n",
            "mini-batch  9  loss is:  tensor(-1242.0090)\n",
            "mini-batch  0  loss is:  tensor(-914.7230)\n",
            "mini-batch  1  loss is:  tensor(-1197.0659)\n",
            "mini-batch  2  loss is:  tensor(-1416.2427)\n",
            "mini-batch  3  loss is:  tensor(-564.1873)\n",
            "mini-batch  4  loss is:  tensor(-1825.2612)\n",
            "mini-batch  5  loss is:  tensor(-852.4912)\n",
            "mini-batch  6  loss is:  tensor(-973.0029)\n",
            "mini-batch  7  loss is:  tensor(-708.6325)\n",
            "mini-batch  8  loss is:  tensor(-899.4073)\n",
            "mini-batch  9  loss is:  tensor(-1110.0530)\n",
            "collect big batch - iteration number  2\n",
            "mini-batch  0  loss is:  tensor(-1324.2935)\n",
            "mini-batch  1  loss is:  tensor(-1399.2816)\n",
            "mini-batch  2  loss is:  tensor(-998.6547)\n",
            "mini-batch  3  loss is:  tensor(-626.3640)\n",
            "mini-batch  4  loss is:  tensor(-1446.3101)\n",
            "mini-batch  5  loss is:  tensor(-893.8024)\n",
            "mini-batch  6  loss is:  tensor(-1294.1965)\n",
            "mini-batch  7  loss is:  tensor(-1318.5209)\n",
            "mini-batch  8  loss is:  tensor(-705.7402)\n",
            "mini-batch  9  loss is:  tensor(-835.5933)\n",
            "mini-batch  0  loss is:  tensor(-1059.4855)\n",
            "mini-batch  1  loss is:  tensor(-1035.9260)\n",
            "mini-batch  2  loss is:  tensor(-1564.9822)\n",
            "mini-batch  3  loss is:  tensor(-635.9705)\n",
            "mini-batch  4  loss is:  tensor(-902.8850)\n",
            "mini-batch  5  loss is:  tensor(-838.6625)\n",
            "mini-batch  6  loss is:  tensor(-912.1832)\n",
            "mini-batch  7  loss is:  tensor(-927.5260)\n",
            "mini-batch  8  loss is:  tensor(-604.5409)\n",
            "mini-batch  9  loss is:  tensor(-965.1161)\n",
            "mini-batch  0  loss is:  tensor(-982.9462)\n",
            "mini-batch  1  loss is:  tensor(-1218.3093)\n",
            "mini-batch  2  loss is:  tensor(-1511.6497)\n",
            "mini-batch  3  loss is:  tensor(-1395.7992)\n",
            "mini-batch  4  loss is:  tensor(-1366.5299)\n",
            "mini-batch  5  loss is:  tensor(-838.9863)\n",
            "mini-batch  6  loss is:  tensor(-851.1719)\n",
            "mini-batch  7  loss is:  tensor(-1377.5579)\n",
            "mini-batch  8  loss is:  tensor(-658.7315)\n",
            "mini-batch  9  loss is:  tensor(-1622.5950)\n",
            "mini-batch  0  loss is:  tensor(-832.6296)\n",
            "mini-batch  1  loss is:  tensor(-693.0437)\n",
            "mini-batch  2  loss is:  tensor(-1059.3186)\n",
            "mini-batch  3  loss is:  tensor(-808.7889)\n",
            "mini-batch  4  loss is:  tensor(-783.8920)\n",
            "mini-batch  5  loss is:  tensor(-1508.1821)\n",
            "mini-batch  6  loss is:  tensor(-1484.3535)\n",
            "mini-batch  7  loss is:  tensor(-1525.0333)\n",
            "mini-batch  8  loss is:  tensor(-784.3032)\n",
            "mini-batch  9  loss is:  tensor(-1573.4756)\n",
            "mini-batch  0  loss is:  tensor(-1816.6981)\n",
            "mini-batch  1  loss is:  tensor(-1023.2979)\n",
            "mini-batch  2  loss is:  tensor(-1259.1121)\n",
            "mini-batch  3  loss is:  tensor(-984.1129)\n",
            "mini-batch  4  loss is:  tensor(-844.8696)\n",
            "mini-batch  5  loss is:  tensor(-999.8578)\n",
            "mini-batch  6  loss is:  tensor(-1408.6323)\n",
            "mini-batch  7  loss is:  tensor(-1384.7833)\n",
            "mini-batch  8  loss is:  tensor(-1841.8379)\n",
            "mini-batch  9  loss is:  tensor(-1934.8563)\n",
            "mini-batch  0  loss is:  tensor(-990.4631)\n",
            "mini-batch  1  loss is:  tensor(-691.8737)\n",
            "mini-batch  2  loss is:  tensor(-553.3586)\n",
            "mini-batch  3  loss is:  tensor(-1543.0779)\n",
            "mini-batch  4  loss is:  tensor(-770.3550)\n",
            "mini-batch  5  loss is:  tensor(-541.3137)\n",
            "mini-batch  6  loss is:  tensor(-967.5997)\n",
            "mini-batch  7  loss is:  tensor(-978.0281)\n",
            "mini-batch  8  loss is:  tensor(-1614.3547)\n",
            "mini-batch  9  loss is:  tensor(-1084.1849)\n",
            "mini-batch  0  loss is:  tensor(-1323.2373)\n",
            "mini-batch  1  loss is:  tensor(-873.0388)\n",
            "mini-batch  2  loss is:  tensor(-696.2642)\n",
            "mini-batch  3  loss is:  tensor(-1270.9301)\n",
            "mini-batch  4  loss is:  tensor(-1205.0566)\n",
            "mini-batch  5  loss is:  tensor(-1480.3486)\n",
            "mini-batch  6  loss is:  tensor(-1459.3453)\n",
            "mini-batch  7  loss is:  tensor(-1088.4193)\n",
            "mini-batch  8  loss is:  tensor(-1600.6802)\n",
            "mini-batch  9  loss is:  tensor(-985.2326)\n",
            "mini-batch  0  loss is:  tensor(-1184.2653)\n",
            "mini-batch  1  loss is:  tensor(-690.9617)\n",
            "mini-batch  2  loss is:  tensor(-835.7866)\n",
            "mini-batch  3  loss is:  tensor(-560.6050)\n",
            "mini-batch  4  loss is:  tensor(-1290.6451)\n",
            "mini-batch  5  loss is:  tensor(-969.9268)\n",
            "mini-batch  6  loss is:  tensor(-1005.2913)\n",
            "mini-batch  7  loss is:  tensor(-738.0868)\n",
            "mini-batch  8  loss is:  tensor(-1198.8995)\n",
            "mini-batch  9  loss is:  tensor(-635.1258)\n",
            "mini-batch  0  loss is:  tensor(-698.4499)\n",
            "mini-batch  1  loss is:  tensor(-1328.9980)\n",
            "mini-batch  2  loss is:  tensor(-1164.5128)\n",
            "mini-batch  3  loss is:  tensor(-852.3539)\n",
            "mini-batch  4  loss is:  tensor(-868.8501)\n",
            "mini-batch  5  loss is:  tensor(-1062.0610)\n",
            "mini-batch  6  loss is:  tensor(-1054.8015)\n",
            "mini-batch  7  loss is:  tensor(-988.2642)\n",
            "mini-batch  8  loss is:  tensor(-632.0592)\n",
            "mini-batch  9  loss is:  tensor(-1126.1038)\n",
            "mini-batch  0  loss is:  tensor(-1058.7079)\n",
            "mini-batch  1  loss is:  tensor(-1080.0751)\n",
            "mini-batch  2  loss is:  tensor(-805.5909)\n",
            "mini-batch  3  loss is:  tensor(-771.3287)\n",
            "mini-batch  4  loss is:  tensor(-1169.9700)\n",
            "mini-batch  5  loss is:  tensor(-922.4420)\n",
            "mini-batch  6  loss is:  tensor(-1023.5346)\n",
            "mini-batch  7  loss is:  tensor(-845.7565)\n",
            "mini-batch  8  loss is:  tensor(-916.1812)\n",
            "mini-batch  9  loss is:  tensor(-630.7449)\n",
            "collect big batch - iteration number  3\n",
            "mini-batch  0  loss is:  tensor(-699.1544)\n",
            "mini-batch  1  loss is:  tensor(-684.0880)\n",
            "mini-batch  2  loss is:  tensor(-562.9502)\n",
            "mini-batch  3  loss is:  tensor(-790.3729)\n",
            "mini-batch  4  loss is:  tensor(-796.8380)\n",
            "mini-batch  5  loss is:  tensor(-589.2413)\n",
            "mini-batch  6  loss is:  tensor(-683.8661)\n",
            "mini-batch  7  loss is:  tensor(-692.5493)\n",
            "mini-batch  8  loss is:  tensor(-700.7527)\n",
            "mini-batch  9  loss is:  tensor(-819.7861)\n",
            "mini-batch  0  loss is:  tensor(-809.0414)\n",
            "mini-batch  1  loss is:  tensor(-752.3872)\n",
            "mini-batch  2  loss is:  tensor(-765.0457)\n",
            "mini-batch  3  loss is:  tensor(-582.6801)\n",
            "mini-batch  4  loss is:  tensor(-602.2171)\n",
            "mini-batch  5  loss is:  tensor(-630.0972)\n",
            "mini-batch  6  loss is:  tensor(-703.7338)\n",
            "mini-batch  7  loss is:  tensor(-721.2936)\n",
            "mini-batch  8  loss is:  tensor(-781.8460)\n",
            "mini-batch  9  loss is:  tensor(-690.9981)\n",
            "mini-batch  0  loss is:  tensor(-658.5540)\n",
            "mini-batch  1  loss is:  tensor(-779.2650)\n",
            "mini-batch  2  loss is:  tensor(-738.2997)\n",
            "mini-batch  3  loss is:  tensor(-697.6919)\n",
            "mini-batch  4  loss is:  tensor(-621.3092)\n",
            "mini-batch  5  loss is:  tensor(-608.1306)\n",
            "mini-batch  6  loss is:  tensor(-669.4572)\n",
            "mini-batch  7  loss is:  tensor(-708.2542)\n",
            "mini-batch  8  loss is:  tensor(-807.2807)\n",
            "mini-batch  9  loss is:  tensor(-671.1052)\n",
            "mini-batch  0  loss is:  tensor(-864.5269)\n",
            "mini-batch  1  loss is:  tensor(-445.2466)\n",
            "mini-batch  2  loss is:  tensor(-528.6384)\n",
            "mini-batch  3  loss is:  tensor(-790.4684)\n",
            "mini-batch  4  loss is:  tensor(-790.1430)\n",
            "mini-batch  5  loss is:  tensor(-859.1729)\n",
            "mini-batch  6  loss is:  tensor(-627.1019)\n",
            "mini-batch  7  loss is:  tensor(-1078.7792)\n",
            "mini-batch  8  loss is:  tensor(-860.8830)\n",
            "mini-batch  9  loss is:  tensor(-639.6898)\n",
            "mini-batch  0  loss is:  tensor(-645.7758)\n",
            "mini-batch  1  loss is:  tensor(-1072.7819)\n",
            "mini-batch  2  loss is:  tensor(-812.4229)\n",
            "mini-batch  3  loss is:  tensor(-488.6448)\n",
            "mini-batch  4  loss is:  tensor(-670.3945)\n",
            "mini-batch  5  loss is:  tensor(-821.8663)\n",
            "mini-batch  6  loss is:  tensor(-663.4373)\n",
            "mini-batch  7  loss is:  tensor(-558.9536)\n",
            "mini-batch  8  loss is:  tensor(-661.7072)\n",
            "mini-batch  9  loss is:  tensor(-696.2194)\n",
            "mini-batch  0  loss is:  tensor(-698.2473)\n",
            "mini-batch  1  loss is:  tensor(-367.0365)\n",
            "mini-batch  2  loss is:  tensor(-698.1890)\n",
            "mini-batch  3  loss is:  tensor(-575.9371)\n",
            "mini-batch  4  loss is:  tensor(-746.2969)\n",
            "mini-batch  5  loss is:  tensor(-836.7599)\n",
            "mini-batch  6  loss is:  tensor(-416.1823)\n",
            "mini-batch  7  loss is:  tensor(-497.0369)\n",
            "mini-batch  8  loss is:  tensor(-813.3007)\n",
            "mini-batch  9  loss is:  tensor(-813.3972)\n",
            "mini-batch  0  loss is:  tensor(-541.4056)\n",
            "mini-batch  1  loss is:  tensor(-752.7806)\n",
            "mini-batch  2  loss is:  tensor(-515.3698)\n",
            "mini-batch  3  loss is:  tensor(-654.7093)\n",
            "mini-batch  4  loss is:  tensor(-838.0164)\n",
            "mini-batch  5  loss is:  tensor(-604.7468)\n",
            "mini-batch  6  loss is:  tensor(-743.8433)\n",
            "mini-batch  7  loss is:  tensor(-723.6375)\n",
            "mini-batch  8  loss is:  tensor(-858.6431)\n",
            "mini-batch  9  loss is:  tensor(-936.0947)\n",
            "mini-batch  0  loss is:  tensor(-485.7803)\n",
            "mini-batch  1  loss is:  tensor(-862.6296)\n",
            "mini-batch  2  loss is:  tensor(-572.3546)\n",
            "mini-batch  3  loss is:  tensor(-720.5612)\n",
            "mini-batch  4  loss is:  tensor(-596.9257)\n",
            "mini-batch  5  loss is:  tensor(-638.2405)\n",
            "mini-batch  6  loss is:  tensor(-693.4499)\n",
            "mini-batch  7  loss is:  tensor(-725.3768)\n",
            "mini-batch  8  loss is:  tensor(-747.3276)\n",
            "mini-batch  9  loss is:  tensor(-482.4111)\n",
            "mini-batch  0  loss is:  tensor(-622.9280)\n",
            "mini-batch  1  loss is:  tensor(-571.0818)\n",
            "mini-batch  2  loss is:  tensor(-862.0135)\n",
            "mini-batch  3  loss is:  tensor(-624.4779)\n",
            "mini-batch  4  loss is:  tensor(-762.0807)\n",
            "mini-batch  5  loss is:  tensor(-756.8008)\n",
            "mini-batch  6  loss is:  tensor(-773.0834)\n",
            "mini-batch  7  loss is:  tensor(-669.4930)\n",
            "mini-batch  8  loss is:  tensor(-677.4598)\n",
            "mini-batch  9  loss is:  tensor(-788.2224)\n",
            "mini-batch  0  loss is:  tensor(-508.2375)\n",
            "mini-batch  1  loss is:  tensor(-579.6953)\n",
            "mini-batch  2  loss is:  tensor(-588.9004)\n",
            "mini-batch  3  loss is:  tensor(-736.4239)\n",
            "mini-batch  4  loss is:  tensor(-638.7546)\n",
            "mini-batch  5  loss is:  tensor(-641.8671)\n",
            "mini-batch  6  loss is:  tensor(-533.3049)\n",
            "mini-batch  7  loss is:  tensor(-673.4164)\n",
            "mini-batch  8  loss is:  tensor(-733.5371)\n",
            "mini-batch  9  loss is:  tensor(-667.3828)\n",
            "collect big batch - iteration number  4\n",
            "mini-batch  0  loss is:  tensor(-2236.1997)\n",
            "mini-batch  1  loss is:  tensor(-1296.7244)\n",
            "mini-batch  2  loss is:  tensor(-2012.4524)\n",
            "mini-batch  3  loss is:  tensor(-2973.5190)\n",
            "mini-batch  4  loss is:  tensor(-2688.5942)\n",
            "mini-batch  5  loss is:  tensor(-2055.3794)\n",
            "mini-batch  6  loss is:  tensor(-2766.9390)\n",
            "mini-batch  7  loss is:  tensor(-2082.5828)\n",
            "mini-batch  8  loss is:  tensor(-1002.3956)\n",
            "mini-batch  9  loss is:  tensor(-1918.3992)\n",
            "mini-batch  0  loss is:  tensor(-2535.4861)\n",
            "mini-batch  1  loss is:  tensor(-931.8873)\n",
            "mini-batch  2  loss is:  tensor(-1042.3259)\n",
            "mini-batch  3  loss is:  tensor(-3388.6272)\n",
            "mini-batch  4  loss is:  tensor(-1778.3002)\n",
            "mini-batch  5  loss is:  tensor(-2819.5403)\n",
            "mini-batch  6  loss is:  tensor(-1505.3142)\n",
            "mini-batch  7  loss is:  tensor(-3238.5066)\n",
            "mini-batch  8  loss is:  tensor(-2316.8645)\n",
            "mini-batch  9  loss is:  tensor(-2937.3591)\n",
            "mini-batch  0  loss is:  tensor(-3108.4304)\n",
            "mini-batch  1  loss is:  tensor(-3237.0203)\n",
            "mini-batch  2  loss is:  tensor(-2451.8638)\n",
            "mini-batch  3  loss is:  tensor(-1756.7474)\n",
            "mini-batch  4  loss is:  tensor(-1932.9241)\n",
            "mini-batch  5  loss is:  tensor(-2209.2324)\n",
            "mini-batch  6  loss is:  tensor(-2020.7356)\n",
            "mini-batch  7  loss is:  tensor(-3418.5527)\n",
            "mini-batch  8  loss is:  tensor(-2244.9927)\n",
            "mini-batch  9  loss is:  tensor(-1772.7877)\n",
            "mini-batch  0  loss is:  tensor(-1098.7500)\n",
            "mini-batch  1  loss is:  tensor(-2172.1040)\n",
            "mini-batch  2  loss is:  tensor(-1303.0483)\n",
            "mini-batch  3  loss is:  tensor(-2008.3962)\n",
            "mini-batch  4  loss is:  tensor(-1653.1514)\n",
            "mini-batch  5  loss is:  tensor(-3791.3323)\n",
            "mini-batch  6  loss is:  tensor(-1575.2850)\n",
            "mini-batch  7  loss is:  tensor(-1677.8461)\n",
            "mini-batch  8  loss is:  tensor(-1970.6935)\n",
            "mini-batch  9  loss is:  tensor(-805.3247)\n",
            "mini-batch  0  loss is:  tensor(-2243.0581)\n",
            "mini-batch  1  loss is:  tensor(-2850.1995)\n",
            "mini-batch  2  loss is:  tensor(-1694.1394)\n",
            "mini-batch  3  loss is:  tensor(-2331.0913)\n",
            "mini-batch  4  loss is:  tensor(-1959.4294)\n",
            "mini-batch  5  loss is:  tensor(-2684.8457)\n",
            "mini-batch  6  loss is:  tensor(-3033.3127)\n",
            "mini-batch  7  loss is:  tensor(-1542.0288)\n",
            "mini-batch  8  loss is:  tensor(-3778.0918)\n",
            "mini-batch  9  loss is:  tensor(-1498.8130)\n",
            "mini-batch  0  loss is:  tensor(-1212.0366)\n",
            "mini-batch  1  loss is:  tensor(-1239.8381)\n",
            "mini-batch  2  loss is:  tensor(-797.2836)\n",
            "mini-batch  3  loss is:  tensor(-1504.5687)\n",
            "mini-batch  4  loss is:  tensor(-2493.3899)\n",
            "mini-batch  5  loss is:  tensor(-3112.4243)\n",
            "mini-batch  6  loss is:  tensor(-2109.7175)\n",
            "mini-batch  7  loss is:  tensor(-2720.6660)\n",
            "mini-batch  8  loss is:  tensor(-2765.9067)\n",
            "mini-batch  9  loss is:  tensor(-1611.9626)\n",
            "mini-batch  0  loss is:  tensor(-2006.6038)\n",
            "mini-batch  1  loss is:  tensor(-1231.0177)\n",
            "mini-batch  2  loss is:  tensor(-1760.0046)\n",
            "mini-batch  3  loss is:  tensor(-1576.5756)\n",
            "mini-batch  4  loss is:  tensor(-1990.8655)\n",
            "mini-batch  5  loss is:  tensor(-1872.3988)\n",
            "mini-batch  6  loss is:  tensor(-1643.0745)\n",
            "mini-batch  7  loss is:  tensor(-1077.9890)\n",
            "mini-batch  8  loss is:  tensor(-2674.1953)\n",
            "mini-batch  9  loss is:  tensor(-2418.8726)\n",
            "mini-batch  0  loss is:  tensor(-1722.1038)\n",
            "mini-batch  1  loss is:  tensor(-1481.0293)\n",
            "mini-batch  2  loss is:  tensor(-1583.8330)\n",
            "mini-batch  3  loss is:  tensor(-2363.9434)\n",
            "mini-batch  4  loss is:  tensor(-3394.0728)\n",
            "mini-batch  5  loss is:  tensor(-1411.6158)\n",
            "mini-batch  6  loss is:  tensor(-3043.3955)\n",
            "mini-batch  7  loss is:  tensor(-1056.9413)\n",
            "mini-batch  8  loss is:  tensor(-1179.8580)\n",
            "mini-batch  9  loss is:  tensor(-2367.0005)\n",
            "mini-batch  0  loss is:  tensor(-1453.5717)\n",
            "mini-batch  1  loss is:  tensor(-1874.5520)\n",
            "mini-batch  2  loss is:  tensor(-1858.6643)\n",
            "mini-batch  3  loss is:  tensor(-2895.5593)\n",
            "mini-batch  4  loss is:  tensor(-1386.9288)\n",
            "mini-batch  5  loss is:  tensor(-1942.1438)\n",
            "mini-batch  6  loss is:  tensor(-3009.8147)\n",
            "mini-batch  7  loss is:  tensor(-2677.4150)\n",
            "mini-batch  8  loss is:  tensor(-2215.2280)\n",
            "mini-batch  9  loss is:  tensor(-2845.6462)\n",
            "mini-batch  0  loss is:  tensor(-2244.5088)\n",
            "mini-batch  1  loss is:  tensor(-2427.4524)\n",
            "mini-batch  2  loss is:  tensor(-3364.0034)\n",
            "mini-batch  3  loss is:  tensor(-1799.8669)\n",
            "mini-batch  4  loss is:  tensor(-1109.7937)\n",
            "mini-batch  5  loss is:  tensor(-1742.8870)\n",
            "mini-batch  6  loss is:  tensor(-3481.8252)\n",
            "mini-batch  7  loss is:  tensor(-2290.5596)\n",
            "mini-batch  8  loss is:  tensor(-2267.0020)\n",
            "mini-batch  9  loss is:  tensor(-1915.1792)\n",
            "collect big batch - iteration number  5\n",
            "mini-batch  0  loss is:  tensor(-863.0402)\n",
            "mini-batch  1  loss is:  tensor(-1213.5500)\n",
            "mini-batch  2  loss is:  tensor(-1442.5907)\n",
            "mini-batch  3  loss is:  tensor(-1109.7234)\n",
            "mini-batch  4  loss is:  tensor(-918.1349)\n",
            "mini-batch  5  loss is:  tensor(-1172.2950)\n",
            "mini-batch  6  loss is:  tensor(-682.9327)\n",
            "mini-batch  7  loss is:  tensor(-1206.3064)\n",
            "mini-batch  8  loss is:  tensor(-653.3917)\n",
            "mini-batch  9  loss is:  tensor(-960.9346)\n",
            "mini-batch  0  loss is:  tensor(-746.8588)\n",
            "mini-batch  1  loss is:  tensor(-709.0245)\n",
            "mini-batch  2  loss is:  tensor(-1022.1119)\n",
            "mini-batch  3  loss is:  tensor(-1027.2996)\n",
            "mini-batch  4  loss is:  tensor(-754.3206)\n",
            "mini-batch  5  loss is:  tensor(-1172.7395)\n",
            "mini-batch  6  loss is:  tensor(-1051.6547)\n",
            "mini-batch  7  loss is:  tensor(-1137.1923)\n",
            "mini-batch  8  loss is:  tensor(-1474.6798)\n",
            "mini-batch  9  loss is:  tensor(-1079.4178)\n",
            "mini-batch  0  loss is:  tensor(-1047.0941)\n",
            "mini-batch  1  loss is:  tensor(-1124.7311)\n",
            "mini-batch  2  loss is:  tensor(-581.5774)\n",
            "mini-batch  3  loss is:  tensor(-837.8412)\n",
            "mini-batch  4  loss is:  tensor(-1602.0365)\n",
            "mini-batch  5  loss is:  tensor(-1101.6825)\n",
            "mini-batch  6  loss is:  tensor(-1204.2513)\n",
            "mini-batch  7  loss is:  tensor(-1408.9583)\n",
            "mini-batch  8  loss is:  tensor(-737.6542)\n",
            "mini-batch  9  loss is:  tensor(-974.6915)\n",
            "mini-batch  0  loss is:  tensor(-1079.1545)\n",
            "mini-batch  1  loss is:  tensor(-609.0754)\n",
            "mini-batch  2  loss is:  tensor(-1088.3242)\n",
            "mini-batch  3  loss is:  tensor(-651.6274)\n",
            "mini-batch  4  loss is:  tensor(-707.5037)\n",
            "mini-batch  5  loss is:  tensor(-1597.3883)\n",
            "mini-batch  6  loss is:  tensor(-1297.4377)\n",
            "mini-batch  7  loss is:  tensor(-924.0707)\n",
            "mini-batch  8  loss is:  tensor(-1420.3187)\n",
            "mini-batch  9  loss is:  tensor(-699.7452)\n",
            "mini-batch  0  loss is:  tensor(-903.1377)\n",
            "mini-batch  1  loss is:  tensor(-1247.1007)\n",
            "mini-batch  2  loss is:  tensor(-1403.5751)\n",
            "mini-batch  3  loss is:  tensor(-1443.5909)\n",
            "mini-batch  4  loss is:  tensor(-841.4408)\n",
            "mini-batch  5  loss is:  tensor(-934.3502)\n",
            "mini-batch  6  loss is:  tensor(-1031.5000)\n",
            "mini-batch  7  loss is:  tensor(-780.7194)\n",
            "mini-batch  8  loss is:  tensor(-1099.0333)\n",
            "mini-batch  9  loss is:  tensor(-1291.0725)\n",
            "mini-batch  0  loss is:  tensor(-802.5007)\n",
            "mini-batch  1  loss is:  tensor(-554.1411)\n",
            "mini-batch  2  loss is:  tensor(-1330.1130)\n",
            "mini-batch  3  loss is:  tensor(-511.9089)\n",
            "mini-batch  4  loss is:  tensor(-827.8661)\n",
            "mini-batch  5  loss is:  tensor(-716.8549)\n",
            "mini-batch  6  loss is:  tensor(-1128.4094)\n",
            "mini-batch  7  loss is:  tensor(-757.7929)\n",
            "mini-batch  8  loss is:  tensor(-1267.2399)\n",
            "mini-batch  9  loss is:  tensor(-859.0441)\n",
            "mini-batch  0  loss is:  tensor(-1002.7655)\n",
            "mini-batch  1  loss is:  tensor(-739.0289)\n",
            "mini-batch  2  loss is:  tensor(-1048.8419)\n",
            "mini-batch  3  loss is:  tensor(-976.1204)\n",
            "mini-batch  4  loss is:  tensor(-648.2620)\n",
            "mini-batch  5  loss is:  tensor(-1362.6566)\n",
            "mini-batch  6  loss is:  tensor(-826.9359)\n",
            "mini-batch  7  loss is:  tensor(-1022.6596)\n",
            "mini-batch  8  loss is:  tensor(-1132.6960)\n",
            "mini-batch  9  loss is:  tensor(-873.9641)\n",
            "mini-batch  0  loss is:  tensor(-675.2657)\n",
            "mini-batch  1  loss is:  tensor(-813.8779)\n",
            "mini-batch  2  loss is:  tensor(-841.2581)\n",
            "mini-batch  3  loss is:  tensor(-875.0143)\n",
            "mini-batch  4  loss is:  tensor(-1076.1200)\n",
            "mini-batch  5  loss is:  tensor(-964.4001)\n",
            "mini-batch  6  loss is:  tensor(-1620.6511)\n",
            "mini-batch  7  loss is:  tensor(-980.8311)\n",
            "mini-batch  8  loss is:  tensor(-807.5300)\n",
            "mini-batch  9  loss is:  tensor(-960.6896)\n",
            "mini-batch  0  loss is:  tensor(-884.7751)\n",
            "mini-batch  1  loss is:  tensor(-1192.3444)\n",
            "mini-batch  2  loss is:  tensor(-898.2881)\n",
            "mini-batch  3  loss is:  tensor(-1137.7936)\n",
            "mini-batch  4  loss is:  tensor(-1569.3955)\n",
            "mini-batch  5  loss is:  tensor(-1696.3676)\n",
            "mini-batch  6  loss is:  tensor(-724.4672)\n",
            "mini-batch  7  loss is:  tensor(-606.2077)\n",
            "mini-batch  8  loss is:  tensor(-1104.8457)\n",
            "mini-batch  9  loss is:  tensor(-1102.3690)\n",
            "mini-batch  0  loss is:  tensor(-842.7576)\n",
            "mini-batch  1  loss is:  tensor(-1158.7378)\n",
            "mini-batch  2  loss is:  tensor(-748.1388)\n",
            "mini-batch  3  loss is:  tensor(-1027.3313)\n",
            "mini-batch  4  loss is:  tensor(-1151.1652)\n",
            "mini-batch  5  loss is:  tensor(-1226.7786)\n",
            "mini-batch  6  loss is:  tensor(-1250.2589)\n",
            "mini-batch  7  loss is:  tensor(-783.1028)\n",
            "mini-batch  8  loss is:  tensor(-1042.0518)\n",
            "mini-batch  9  loss is:  tensor(-894.3836)\n",
            "collect big batch - iteration number  6\n",
            "mini-batch  0  loss is:  tensor(-1344.1099)\n",
            "mini-batch  1  loss is:  tensor(-1454.4750)\n",
            "mini-batch  2  loss is:  tensor(-936.4725)\n",
            "mini-batch  3  loss is:  tensor(-1394.5205)\n",
            "mini-batch  4  loss is:  tensor(-1384.5535)\n",
            "mini-batch  5  loss is:  tensor(-1009.1468)\n",
            "mini-batch  6  loss is:  tensor(-829.5725)\n",
            "mini-batch  7  loss is:  tensor(-1176.0984)\n",
            "mini-batch  8  loss is:  tensor(-1706.5939)\n",
            "mini-batch  9  loss is:  tensor(-721.8699)\n",
            "mini-batch  0  loss is:  tensor(-1098.5547)\n",
            "mini-batch  1  loss is:  tensor(-928.3512)\n",
            "mini-batch  2  loss is:  tensor(-1023.5922)\n",
            "mini-batch  3  loss is:  tensor(-1158.6355)\n",
            "mini-batch  4  loss is:  tensor(-931.9498)\n",
            "mini-batch  5  loss is:  tensor(-793.9964)\n",
            "mini-batch  6  loss is:  tensor(-868.9773)\n",
            "mini-batch  7  loss is:  tensor(-536.3457)\n",
            "mini-batch  8  loss is:  tensor(-1295.0089)\n",
            "mini-batch  9  loss is:  tensor(-919.1755)\n",
            "mini-batch  0  loss is:  tensor(-685.8195)\n",
            "mini-batch  1  loss is:  tensor(-710.7485)\n",
            "mini-batch  2  loss is:  tensor(-600.9722)\n",
            "mini-batch  3  loss is:  tensor(-1041.6600)\n",
            "mini-batch  4  loss is:  tensor(-1665.8870)\n",
            "mini-batch  5  loss is:  tensor(-515.2386)\n",
            "mini-batch  6  loss is:  tensor(-1239.9757)\n",
            "mini-batch  7  loss is:  tensor(-917.6174)\n",
            "mini-batch  8  loss is:  tensor(-655.3695)\n",
            "mini-batch  9  loss is:  tensor(-1481.2317)\n",
            "mini-batch  0  loss is:  tensor(-2145.6912)\n",
            "mini-batch  1  loss is:  tensor(-1609.5208)\n",
            "mini-batch  2  loss is:  tensor(-1994.8762)\n",
            "mini-batch  3  loss is:  tensor(-723.7588)\n",
            "mini-batch  4  loss is:  tensor(-1064.4849)\n",
            "mini-batch  5  loss is:  tensor(-759.6663)\n",
            "mini-batch  6  loss is:  tensor(-1073.8300)\n",
            "mini-batch  7  loss is:  tensor(-674.0058)\n",
            "mini-batch  8  loss is:  tensor(-685.2054)\n",
            "mini-batch  9  loss is:  tensor(-1015.2339)\n",
            "mini-batch  0  loss is:  tensor(-609.9241)\n",
            "mini-batch  1  loss is:  tensor(-750.7646)\n",
            "mini-batch  2  loss is:  tensor(-1177.2651)\n",
            "mini-batch  3  loss is:  tensor(-1378.7498)\n",
            "mini-batch  4  loss is:  tensor(-1308.2461)\n",
            "mini-batch  5  loss is:  tensor(-1241.4308)\n",
            "mini-batch  6  loss is:  tensor(-1163.7772)\n",
            "mini-batch  7  loss is:  tensor(-592.2651)\n",
            "mini-batch  8  loss is:  tensor(-959.6324)\n",
            "mini-batch  9  loss is:  tensor(-744.3028)\n",
            "mini-batch  0  loss is:  tensor(-1359.0519)\n",
            "mini-batch  1  loss is:  tensor(-1387.1893)\n",
            "mini-batch  2  loss is:  tensor(-480.5706)\n",
            "mini-batch  3  loss is:  tensor(-1045.8798)\n",
            "mini-batch  4  loss is:  tensor(-1061.1083)\n",
            "mini-batch  5  loss is:  tensor(-723.7956)\n",
            "mini-batch  6  loss is:  tensor(-664.6963)\n",
            "mini-batch  7  loss is:  tensor(-564.8405)\n",
            "mini-batch  8  loss is:  tensor(-794.8690)\n",
            "mini-batch  9  loss is:  tensor(-1101.7987)\n",
            "mini-batch  0  loss is:  tensor(-952.0125)\n",
            "mini-batch  1  loss is:  tensor(-495.2816)\n",
            "mini-batch  2  loss is:  tensor(-867.8936)\n",
            "mini-batch  3  loss is:  tensor(-1646.1709)\n",
            "mini-batch  4  loss is:  tensor(-895.7772)\n",
            "mini-batch  5  loss is:  tensor(-1128.9440)\n",
            "mini-batch  6  loss is:  tensor(-1184.3243)\n",
            "mini-batch  7  loss is:  tensor(-577.2351)\n",
            "mini-batch  8  loss is:  tensor(-889.5167)\n",
            "mini-batch  9  loss is:  tensor(-945.6456)\n",
            "mini-batch  0  loss is:  tensor(-1042.9092)\n",
            "mini-batch  1  loss is:  tensor(-784.0333)\n",
            "mini-batch  2  loss is:  tensor(-1365.7786)\n",
            "mini-batch  3  loss is:  tensor(-882.4752)\n",
            "mini-batch  4  loss is:  tensor(-1167.0175)\n",
            "mini-batch  5  loss is:  tensor(-730.2000)\n",
            "mini-batch  6  loss is:  tensor(-1537.1913)\n",
            "mini-batch  7  loss is:  tensor(-886.6295)\n",
            "mini-batch  8  loss is:  tensor(-1254.6776)\n",
            "mini-batch  9  loss is:  tensor(-657.9380)\n",
            "mini-batch  0  loss is:  tensor(-1552.9424)\n",
            "mini-batch  1  loss is:  tensor(-1686.9374)\n",
            "mini-batch  2  loss is:  tensor(-884.4268)\n",
            "mini-batch  3  loss is:  tensor(-1373.2784)\n",
            "mini-batch  4  loss is:  tensor(-996.1274)\n",
            "mini-batch  5  loss is:  tensor(-899.9736)\n",
            "mini-batch  6  loss is:  tensor(-770.2319)\n",
            "mini-batch  7  loss is:  tensor(-1061.0200)\n",
            "mini-batch  8  loss is:  tensor(-1100.9272)\n",
            "mini-batch  9  loss is:  tensor(-940.2778)\n",
            "mini-batch  0  loss is:  tensor(-979.6337)\n",
            "mini-batch  1  loss is:  tensor(-1160.7870)\n",
            "mini-batch  2  loss is:  tensor(-1144.4928)\n",
            "mini-batch  3  loss is:  tensor(-777.9111)\n",
            "mini-batch  4  loss is:  tensor(-1102.7069)\n",
            "mini-batch  5  loss is:  tensor(-630.7637)\n",
            "mini-batch  6  loss is:  tensor(-1101.9236)\n",
            "mini-batch  7  loss is:  tensor(-1539.3677)\n",
            "mini-batch  8  loss is:  tensor(-1897.9601)\n",
            "mini-batch  9  loss is:  tensor(-685.3321)\n",
            "collect big batch - iteration number  7\n",
            "mini-batch  0  loss is:  tensor(-3162.3276)\n",
            "mini-batch  1  loss is:  tensor(-2661.2908)\n",
            "mini-batch  2  loss is:  tensor(-3016.1040)\n",
            "mini-batch  3  loss is:  tensor(-4229.6719)\n",
            "mini-batch  4  loss is:  tensor(-1429.8082)\n",
            "mini-batch  5  loss is:  tensor(-2152.0610)\n",
            "mini-batch  6  loss is:  tensor(-2965.6621)\n",
            "mini-batch  7  loss is:  tensor(-2135.7031)\n",
            "mini-batch  8  loss is:  tensor(-1678.7881)\n",
            "mini-batch  9  loss is:  tensor(-3159.3542)\n",
            "mini-batch  0  loss is:  tensor(-2435.3477)\n",
            "mini-batch  1  loss is:  tensor(-2663.4927)\n",
            "mini-batch  2  loss is:  tensor(-2861.4924)\n",
            "mini-batch  3  loss is:  tensor(-2400.1570)\n",
            "mini-batch  4  loss is:  tensor(-2611.4939)\n",
            "mini-batch  5  loss is:  tensor(-2903.1934)\n",
            "mini-batch  6  loss is:  tensor(-3272.3337)\n",
            "mini-batch  7  loss is:  tensor(-2343.7480)\n",
            "mini-batch  8  loss is:  tensor(-3285.6736)\n",
            "mini-batch  9  loss is:  tensor(-2199.8911)\n",
            "mini-batch  0  loss is:  tensor(-3122.1287)\n",
            "mini-batch  1  loss is:  tensor(-2815.2581)\n",
            "mini-batch  2  loss is:  tensor(-3146.7190)\n",
            "mini-batch  3  loss is:  tensor(-2479.4746)\n",
            "mini-batch  4  loss is:  tensor(-1869.9602)\n",
            "mini-batch  5  loss is:  tensor(-3184.0354)\n",
            "mini-batch  6  loss is:  tensor(-2380.1299)\n",
            "mini-batch  7  loss is:  tensor(-2956.6819)\n",
            "mini-batch  8  loss is:  tensor(-2266.2639)\n",
            "mini-batch  9  loss is:  tensor(-2077.9280)\n",
            "mini-batch  0  loss is:  tensor(-3429.6133)\n",
            "mini-batch  1  loss is:  tensor(-3379.8628)\n",
            "mini-batch  2  loss is:  tensor(-2802.2676)\n",
            "mini-batch  3  loss is:  tensor(-2685.4626)\n",
            "mini-batch  4  loss is:  tensor(-2342.3894)\n",
            "mini-batch  5  loss is:  tensor(-2795.7261)\n",
            "mini-batch  6  loss is:  tensor(-2874.8682)\n",
            "mini-batch  7  loss is:  tensor(-3086.2188)\n",
            "mini-batch  8  loss is:  tensor(-2275.3430)\n",
            "mini-batch  9  loss is:  tensor(-2477.4863)\n",
            "mini-batch  0  loss is:  tensor(-2725.3264)\n",
            "mini-batch  1  loss is:  tensor(-2397.5957)\n",
            "mini-batch  2  loss is:  tensor(-2734.7349)\n",
            "mini-batch  3  loss is:  tensor(-3659.9531)\n",
            "mini-batch  4  loss is:  tensor(-1989.7245)\n",
            "mini-batch  5  loss is:  tensor(-2624.4651)\n",
            "mini-batch  6  loss is:  tensor(-3161.8442)\n",
            "mini-batch  7  loss is:  tensor(-3302.3650)\n",
            "mini-batch  8  loss is:  tensor(-2167.6716)\n",
            "mini-batch  9  loss is:  tensor(-2749.5713)\n",
            "mini-batch  0  loss is:  tensor(-2955.8127)\n",
            "mini-batch  1  loss is:  tensor(-1340.5743)\n",
            "mini-batch  2  loss is:  tensor(-3525.5017)\n",
            "mini-batch  3  loss is:  tensor(-2542.1404)\n",
            "mini-batch  4  loss is:  tensor(-2975.7607)\n",
            "mini-batch  5  loss is:  tensor(-2418.0823)\n",
            "mini-batch  6  loss is:  tensor(-2422.7341)\n",
            "mini-batch  7  loss is:  tensor(-2572.3049)\n",
            "mini-batch  8  loss is:  tensor(-2263.9060)\n",
            "mini-batch  9  loss is:  tensor(-2917.6272)\n",
            "mini-batch  0  loss is:  tensor(-2087.3691)\n",
            "mini-batch  1  loss is:  tensor(-2975.3220)\n",
            "mini-batch  2  loss is:  tensor(-2518.8623)\n",
            "mini-batch  3  loss is:  tensor(-3300.3748)\n",
            "mini-batch  4  loss is:  tensor(-2177.8711)\n",
            "mini-batch  5  loss is:  tensor(-2588.5496)\n",
            "mini-batch  6  loss is:  tensor(-2472.5769)\n",
            "mini-batch  7  loss is:  tensor(-2243.8230)\n",
            "mini-batch  8  loss is:  tensor(-3031.7366)\n",
            "mini-batch  9  loss is:  tensor(-2658.2434)\n",
            "mini-batch  0  loss is:  tensor(-2642.4558)\n",
            "mini-batch  1  loss is:  tensor(-2006.1620)\n",
            "mini-batch  2  loss is:  tensor(-2151.4827)\n",
            "mini-batch  3  loss is:  tensor(-2408.2705)\n",
            "mini-batch  4  loss is:  tensor(-2325.5632)\n",
            "mini-batch  5  loss is:  tensor(-1887.0925)\n",
            "mini-batch  6  loss is:  tensor(-2422.6824)\n",
            "mini-batch  7  loss is:  tensor(-2551.8147)\n",
            "mini-batch  8  loss is:  tensor(-2791.9299)\n",
            "mini-batch  9  loss is:  tensor(-2034.6405)\n",
            "mini-batch  0  loss is:  tensor(-3501.0898)\n",
            "mini-batch  1  loss is:  tensor(-1893.1290)\n",
            "mini-batch  2  loss is:  tensor(-1691.2256)\n",
            "mini-batch  3  loss is:  tensor(-2633.6389)\n",
            "mini-batch  4  loss is:  tensor(-3393.6958)\n",
            "mini-batch  5  loss is:  tensor(-2934.9983)\n",
            "mini-batch  6  loss is:  tensor(-2305.8418)\n",
            "mini-batch  7  loss is:  tensor(-2507.6755)\n",
            "mini-batch  8  loss is:  tensor(-2048.6082)\n",
            "mini-batch  9  loss is:  tensor(-3021.4939)\n",
            "mini-batch  0  loss is:  tensor(-2226.1331)\n",
            "mini-batch  1  loss is:  tensor(-1674.6581)\n",
            "mini-batch  2  loss is:  tensor(-2264.4436)\n",
            "mini-batch  3  loss is:  tensor(-2734.3638)\n",
            "mini-batch  4  loss is:  tensor(-2348.2920)\n",
            "mini-batch  5  loss is:  tensor(-3630.5801)\n",
            "mini-batch  6  loss is:  tensor(-2835.8623)\n",
            "mini-batch  7  loss is:  tensor(-2320.9065)\n",
            "mini-batch  8  loss is:  tensor(-2573.6394)\n",
            "mini-batch  9  loss is:  tensor(-3695.9102)\n",
            "collect big batch - iteration number  8\n",
            "mini-batch  0  loss is:  tensor(-1552.7928)\n",
            "mini-batch  1  loss is:  tensor(-1402.9895)\n",
            "mini-batch  2  loss is:  tensor(-2208.9849)\n",
            "mini-batch  3  loss is:  tensor(-1115.2715)\n",
            "mini-batch  4  loss is:  tensor(-1855.7834)\n",
            "mini-batch  5  loss is:  tensor(-2220.0364)\n",
            "mini-batch  6  loss is:  tensor(-1599.2103)\n",
            "mini-batch  7  loss is:  tensor(-1177.0822)\n",
            "mini-batch  8  loss is:  tensor(-2875.3320)\n",
            "mini-batch  9  loss is:  tensor(-1986.3948)\n",
            "mini-batch  0  loss is:  tensor(-1156.7781)\n",
            "mini-batch  1  loss is:  tensor(-2374.0093)\n",
            "mini-batch  2  loss is:  tensor(-1712.6075)\n",
            "mini-batch  3  loss is:  tensor(-2482.4626)\n",
            "mini-batch  4  loss is:  tensor(-1478.4678)\n",
            "mini-batch  5  loss is:  tensor(-2713.6958)\n",
            "mini-batch  6  loss is:  tensor(-1806.6354)\n",
            "mini-batch  7  loss is:  tensor(-1196.1389)\n",
            "mini-batch  8  loss is:  tensor(-2580.6694)\n",
            "mini-batch  9  loss is:  tensor(-1396.9269)\n",
            "mini-batch  0  loss is:  tensor(-1882.1694)\n",
            "mini-batch  1  loss is:  tensor(-2281.2395)\n",
            "mini-batch  2  loss is:  tensor(-5559.7939)\n",
            "mini-batch  3  loss is:  tensor(-1604.2122)\n",
            "mini-batch  4  loss is:  tensor(-1352.4990)\n",
            "mini-batch  5  loss is:  tensor(-1980.1890)\n",
            "mini-batch  6  loss is:  tensor(-1328.0459)\n",
            "mini-batch  7  loss is:  tensor(-2546.8838)\n",
            "mini-batch  8  loss is:  tensor(-1299.4791)\n",
            "mini-batch  9  loss is:  tensor(-1144.8984)\n",
            "mini-batch  0  loss is:  tensor(-2020.1458)\n",
            "mini-batch  1  loss is:  tensor(-1110.9208)\n",
            "mini-batch  2  loss is:  tensor(-2454.5081)\n",
            "mini-batch  3  loss is:  tensor(-1168.4423)\n",
            "mini-batch  4  loss is:  tensor(-1525.1990)\n",
            "mini-batch  5  loss is:  tensor(-2855.5857)\n",
            "mini-batch  6  loss is:  tensor(-1714.2887)\n",
            "mini-batch  7  loss is:  tensor(-1506.0193)\n",
            "mini-batch  8  loss is:  tensor(-2019.1458)\n",
            "mini-batch  9  loss is:  tensor(-2417.1213)\n",
            "mini-batch  0  loss is:  tensor(-1344.0128)\n",
            "mini-batch  1  loss is:  tensor(-1862.2998)\n",
            "mini-batch  2  loss is:  tensor(-1091.1854)\n",
            "mini-batch  3  loss is:  tensor(-1491.1681)\n",
            "mini-batch  4  loss is:  tensor(-1988.2300)\n",
            "mini-batch  5  loss is:  tensor(-2022.6831)\n",
            "mini-batch  6  loss is:  tensor(-2043.4551)\n",
            "mini-batch  7  loss is:  tensor(-2203.4495)\n",
            "mini-batch  8  loss is:  tensor(-931.2094)\n",
            "mini-batch  9  loss is:  tensor(-1114.8231)\n",
            "mini-batch  0  loss is:  tensor(-2206.3525)\n",
            "mini-batch  1  loss is:  tensor(-1115.0510)\n",
            "mini-batch  2  loss is:  tensor(-1538.6958)\n",
            "mini-batch  3  loss is:  tensor(-2180.8413)\n",
            "mini-batch  4  loss is:  tensor(-2570.1953)\n",
            "mini-batch  5  loss is:  tensor(-2026.4885)\n",
            "mini-batch  6  loss is:  tensor(-2099.5811)\n",
            "mini-batch  7  loss is:  tensor(-2667.5759)\n",
            "mini-batch  8  loss is:  tensor(-2091.5872)\n",
            "mini-batch  9  loss is:  tensor(-1655.8268)\n",
            "mini-batch  0  loss is:  tensor(-1006.5654)\n",
            "mini-batch  1  loss is:  tensor(-1874.6704)\n",
            "mini-batch  2  loss is:  tensor(-1789.4314)\n",
            "mini-batch  3  loss is:  tensor(-2085.4314)\n",
            "mini-batch  4  loss is:  tensor(-1615.2715)\n",
            "mini-batch  5  loss is:  tensor(-2353.0127)\n",
            "mini-batch  6  loss is:  tensor(-1688.1849)\n",
            "mini-batch  7  loss is:  tensor(-2019.3317)\n",
            "mini-batch  8  loss is:  tensor(-1625.8359)\n",
            "mini-batch  9  loss is:  tensor(-2539.5776)\n",
            "mini-batch  0  loss is:  tensor(-1379.2183)\n",
            "mini-batch  1  loss is:  tensor(-2297.6387)\n",
            "mini-batch  2  loss is:  tensor(-2239.8560)\n",
            "mini-batch  3  loss is:  tensor(-1643.3026)\n",
            "mini-batch  4  loss is:  tensor(-1697.5490)\n",
            "mini-batch  5  loss is:  tensor(-1791.7406)\n",
            "mini-batch  6  loss is:  tensor(-2341.7488)\n",
            "mini-batch  7  loss is:  tensor(-1444.7043)\n",
            "mini-batch  8  loss is:  tensor(-1562.9093)\n",
            "mini-batch  9  loss is:  tensor(-846.4333)\n",
            "mini-batch  0  loss is:  tensor(-1847.6466)\n",
            "mini-batch  1  loss is:  tensor(-2678.8467)\n",
            "mini-batch  2  loss is:  tensor(-1214.3997)\n",
            "mini-batch  3  loss is:  tensor(-1848.3744)\n",
            "mini-batch  4  loss is:  tensor(-1869.5205)\n",
            "mini-batch  5  loss is:  tensor(-2570.0737)\n",
            "mini-batch  6  loss is:  tensor(-2819.3389)\n",
            "mini-batch  7  loss is:  tensor(-1299.3728)\n",
            "mini-batch  8  loss is:  tensor(-1510.6871)\n",
            "mini-batch  9  loss is:  tensor(-1270.9673)\n",
            "mini-batch  0  loss is:  tensor(-1460.5015)\n",
            "mini-batch  1  loss is:  tensor(-1523.8204)\n",
            "mini-batch  2  loss is:  tensor(-2390.5774)\n",
            "mini-batch  3  loss is:  tensor(-2461.8574)\n",
            "mini-batch  4  loss is:  tensor(-1733.9658)\n",
            "mini-batch  5  loss is:  tensor(-1167.5973)\n",
            "mini-batch  6  loss is:  tensor(-986.9069)\n",
            "mini-batch  7  loss is:  tensor(-1456.4192)\n",
            "mini-batch  8  loss is:  tensor(-2082.0420)\n",
            "mini-batch  9  loss is:  tensor(-1453.1700)\n",
            "collect big batch - iteration number  9\n",
            "mini-batch  0  loss is:  tensor(-2369.3174)\n",
            "mini-batch  1  loss is:  tensor(-2061.7253)\n",
            "mini-batch  2  loss is:  tensor(-1820.9539)\n",
            "mini-batch  3  loss is:  tensor(-1782.8901)\n",
            "mini-batch  4  loss is:  tensor(-1832.6671)\n",
            "mini-batch  5  loss is:  tensor(-1711.4001)\n",
            "mini-batch  6  loss is:  tensor(-1544.7712)\n",
            "mini-batch  7  loss is:  tensor(-3778.5037)\n",
            "mini-batch  8  loss is:  tensor(-1618.6694)\n",
            "mini-batch  9  loss is:  tensor(-2011.5427)\n",
            "mini-batch  0  loss is:  tensor(-2927.5071)\n",
            "mini-batch  1  loss is:  tensor(-1799.4463)\n",
            "mini-batch  2  loss is:  tensor(-2712.2566)\n",
            "mini-batch  3  loss is:  tensor(-2697.5022)\n",
            "mini-batch  4  loss is:  tensor(-2672.9751)\n",
            "mini-batch  5  loss is:  tensor(-1845.8116)\n",
            "mini-batch  6  loss is:  tensor(-1779.1956)\n",
            "mini-batch  7  loss is:  tensor(-2483.2583)\n",
            "mini-batch  8  loss is:  tensor(-1899.6777)\n",
            "mini-batch  9  loss is:  tensor(-1322.9117)\n",
            "mini-batch  0  loss is:  tensor(-3442.9563)\n",
            "mini-batch  1  loss is:  tensor(-2806.3167)\n",
            "mini-batch  2  loss is:  tensor(-2107.8140)\n",
            "mini-batch  3  loss is:  tensor(-1465.7501)\n",
            "mini-batch  4  loss is:  tensor(-2852.5693)\n",
            "mini-batch  5  loss is:  tensor(-2721.0901)\n",
            "mini-batch  6  loss is:  tensor(-2487.5715)\n",
            "mini-batch  7  loss is:  tensor(-1986.3036)\n",
            "mini-batch  8  loss is:  tensor(-2456.3547)\n",
            "mini-batch  9  loss is:  tensor(-2104.7559)\n",
            "mini-batch  0  loss is:  tensor(-3046.2280)\n",
            "mini-batch  1  loss is:  tensor(-1625.8317)\n",
            "mini-batch  2  loss is:  tensor(-2347.6990)\n",
            "mini-batch  3  loss is:  tensor(-2768.1582)\n",
            "mini-batch  4  loss is:  tensor(-2560.1133)\n",
            "mini-batch  5  loss is:  tensor(-2171.4561)\n",
            "mini-batch  6  loss is:  tensor(-3984.4434)\n",
            "mini-batch  7  loss is:  tensor(-2120.3105)\n",
            "mini-batch  8  loss is:  tensor(-2420.7861)\n",
            "mini-batch  9  loss is:  tensor(-1694.7130)\n",
            "mini-batch  0  loss is:  tensor(-2225.7292)\n",
            "mini-batch  1  loss is:  tensor(-2718.3313)\n",
            "mini-batch  2  loss is:  tensor(-2354.2205)\n",
            "mini-batch  3  loss is:  tensor(-3014.3433)\n",
            "mini-batch  4  loss is:  tensor(-2881.9749)\n",
            "mini-batch  5  loss is:  tensor(-2780.7681)\n",
            "mini-batch  6  loss is:  tensor(-3225.2241)\n",
            "mini-batch  7  loss is:  tensor(-2074.3335)\n",
            "mini-batch  8  loss is:  tensor(-3174.5369)\n",
            "mini-batch  9  loss is:  tensor(-3183.4355)\n",
            "mini-batch  0  loss is:  tensor(-2141.5898)\n",
            "mini-batch  1  loss is:  tensor(-2132.6506)\n",
            "mini-batch  2  loss is:  tensor(-3721.1089)\n",
            "mini-batch  3  loss is:  tensor(-2077.4844)\n",
            "mini-batch  4  loss is:  tensor(-2411.7495)\n",
            "mini-batch  5  loss is:  tensor(-2517.7012)\n",
            "mini-batch  6  loss is:  tensor(-3936.0498)\n",
            "mini-batch  7  loss is:  tensor(-3045.6401)\n",
            "mini-batch  8  loss is:  tensor(-3100.3420)\n",
            "mini-batch  9  loss is:  tensor(-2691.8193)\n",
            "mini-batch  0  loss is:  tensor(-1842.3303)\n",
            "mini-batch  1  loss is:  tensor(-2071.0166)\n",
            "mini-batch  2  loss is:  tensor(-2749.5444)\n",
            "mini-batch  3  loss is:  tensor(-2712.5244)\n",
            "mini-batch  4  loss is:  tensor(-2813.7454)\n",
            "mini-batch  5  loss is:  tensor(-1964.6365)\n",
            "mini-batch  6  loss is:  tensor(-2813.9768)\n",
            "mini-batch  7  loss is:  tensor(-2697.3186)\n",
            "mini-batch  8  loss is:  tensor(-2925.1812)\n",
            "mini-batch  9  loss is:  tensor(-2000.8268)\n",
            "mini-batch  0  loss is:  tensor(-2791.4392)\n",
            "mini-batch  1  loss is:  tensor(-2969.3030)\n",
            "mini-batch  2  loss is:  tensor(-2322.2026)\n",
            "mini-batch  3  loss is:  tensor(-3042.8950)\n",
            "mini-batch  4  loss is:  tensor(-2089.5178)\n",
            "mini-batch  5  loss is:  tensor(-2191.3137)\n",
            "mini-batch  6  loss is:  tensor(-2460.9360)\n",
            "mini-batch  7  loss is:  tensor(-2633.4817)\n",
            "mini-batch  8  loss is:  tensor(-2282.1772)\n",
            "mini-batch  9  loss is:  tensor(-2896.6125)\n",
            "mini-batch  0  loss is:  tensor(-1998.2841)\n",
            "mini-batch  1  loss is:  tensor(-2317.5620)\n",
            "mini-batch  2  loss is:  tensor(-2913.4634)\n",
            "mini-batch  3  loss is:  tensor(-2153.2107)\n",
            "mini-batch  4  loss is:  tensor(-3186.1621)\n",
            "mini-batch  5  loss is:  tensor(-2580.1277)\n",
            "mini-batch  6  loss is:  tensor(-2608.5166)\n",
            "mini-batch  7  loss is:  tensor(-2628.2976)\n",
            "mini-batch  8  loss is:  tensor(-2107.2346)\n",
            "mini-batch  9  loss is:  tensor(-2814.8765)\n",
            "mini-batch  0  loss is:  tensor(-2946.4834)\n",
            "mini-batch  1  loss is:  tensor(-3894.4648)\n",
            "mini-batch  2  loss is:  tensor(-2043.9584)\n",
            "mini-batch  3  loss is:  tensor(-2042.6741)\n",
            "mini-batch  4  loss is:  tensor(-1600.1798)\n",
            "mini-batch  5  loss is:  tensor(-1657.6150)\n",
            "mini-batch  6  loss is:  tensor(-2678.0957)\n",
            "mini-batch  7  loss is:  tensor(-2210.5410)\n",
            "mini-batch  8  loss is:  tensor(-2200.5798)\n",
            "mini-batch  9  loss is:  tensor(-1789.7786)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqXelSMtVUHJ",
        "outputId": "388a2a7f-ce71-420a-f63b-ac04c7f1d7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m(156)\u001b[0;36mbackward\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    154 \u001b[0;31m    Variable._execution_engine.run_backward(\n",
            "\u001b[0m\u001b[0;32m    155 \u001b[0;31m        \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 156 \u001b[0;31m        allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[0m\u001b[0;32m    157 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    158 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> up\n",
            "> \u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m(307)\u001b[0;36mbackward\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    305 \u001b[0;31m                \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    306 \u001b[0;31m                inputs=inputs)\n",
            "\u001b[0m\u001b[0;32m--> 307 \u001b[0;31m        \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    308 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    309 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> up\n",
            "> \u001b[0;32m<ipython-input-21-68440411b210>\u001b[0m(111)\u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    109 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    110 \u001b[0;31m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 111 \u001b[0;31m          \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    112 \u001b[0;31m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    113 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> returns_batch[0].grad_fn\n",
            "ipdb> returns_batch.grad_fn\n",
            "ipdb> returns_batch.requires_grad\n",
            "False\n",
            "ipdb> advantage_batch.grad_fn\n",
            "<ReshapeAliasBackward0 object at 0x7fccf9df6b90>\n",
            "ipdb> exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " x = torch.arange(40).view(10, 4)\n",
        " print(x)\n",
        "torch.flip(x, [0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEr6lx2GEv6A",
        "outputId": "ad5099c5-8bb1-4e06-ad51-a28fc1ed63ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15],\n",
            "        [16, 17, 18, 19],\n",
            "        [20, 21, 22, 23],\n",
            "        [24, 25, 26, 27],\n",
            "        [28, 29, 30, 31],\n",
            "        [32, 33, 34, 35],\n",
            "        [36, 37, 38, 39]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[36, 37, 38, 39],\n",
              "        [32, 33, 34, 35],\n",
              "        [28, 29, 30, 31],\n",
              "        [24, 25, 26, 27],\n",
              "        [20, 21, 22, 23],\n",
              "        [16, 17, 18, 19],\n",
              "        [12, 13, 14, 15],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 0,  1,  2,  3]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad_fn"
      ],
      "metadata": {
        "id": "xgUYegKaV3LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1])\n",
        "torch.no_grad(a)"
      ],
      "metadata": {
        "id": "DLvZDTuDJZCT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "ece4541a-aa36-413f-eb6d-1b31b7ce145f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4571d1f9693b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2])"
      ],
      "metadata": {
        "id": "EjQ85A4o-6xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(10-1, -1, -1):\n",
        "  print(t)"
      ],
      "metadata": {
        "id": "o4nUsnU0AIKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## covariance stuff\n",
        "\n",
        "Src: https://github.com/nikhilbarhate99/PPO-PyTorch/blob/master/PPO_colab.ipynb"
      ],
      "metadata": {
        "id": "oq0kE1aYK881"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.full((2,), 3 * 3)"
      ],
      "metadata": {
        "id": "-CV739BEKnlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.diag(torch.full((2,), 3 * 3)).unsqueeze(dim=0)"
      ],
      "metadata": {
        "id": "H4k6ylE7KrKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sEw_7RnIK5kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PPO:\n",
        "  def __init__(self, config):\n",
        "\n",
        "    self.config = config\n",
        "    # self.num_cpus = multiprocessing.cpu_count()\n",
        "\n",
        "    self.envs = SubprocVecEnv([make_env(config['env_id'], i) for i in range(self.config['num_workers'])])\n",
        "\n",
        "    self.action_dim = self.envs.action_space.shape[0]\n",
        "    self.state_dim = self.envs.observation_space.shape[0]\n",
        "\n",
        "    self.model = ActorCritic(self.state_dim, self.action_dim, config['std_init'])\n",
        "\n",
        "    self.optimizer = torch.optim.Adam(self.model.parameters())\n",
        "\n",
        "  def create_rollout(self):\n",
        "\n",
        "    pass\n",
        "\n",
        "  def train(self): \n",
        "\n",
        "    # num_iterations = Number of updates: \n",
        "    print('train')\n",
        "    for it in range(self.config['num_iterations']):\n",
        "    \n",
        "      obs_batch = torch.zeros((self.config['max_timesteps'], self.config['num_workers'],  self.envs.observation_space.shape[0]))\n",
        "      action_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], self.envs.action_space.shape[0]))\n",
        "      reward_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1))\n",
        "      done_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1))\n",
        "      next_obs_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], self.envs.observation_space.shape[0]))\n",
        "      ratio_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1))\n",
        "      log_prob_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1))\n",
        "      advantage_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1),requires_grad=True)\n",
        "      returns_batch = torch.zeros((self.config['max_timesteps'],self.config['num_workers'], 1))\n",
        "      print('batch')\n",
        "      obs = self.envs.reset()\n",
        "\n",
        "      # capture NT rollouts \n",
        "      for t in range(self.config['max_timesteps']):\n",
        "        print('model')\n",
        "        actions,log_probs = self.model.get_action(torch.tensor(obs))\n",
        "        actions = actions.numpy()\n",
        "\n",
        "        print('env')\n",
        "\n",
        "        self.envs.step_async(actions)\n",
        "        next_obs, rewards, dones, infos = self.envs.step_wait()\n",
        "        \n",
        "        print('gather')\n",
        "\n",
        "        obs_batch[t] = torch.tensor(obs)\n",
        "        action_batch[t] = torch.tensor(actions)\n",
        "        reward_batch[t] = torch.tensor(rewards.reshape(-1,1))\n",
        "        done_batch[t] = torch.tensor(dones.reshape(-1,1))\n",
        "        next_obs_batch[t] = torch.tensor(next_obs)\n",
        "        log_prob_batch[t] = log_probs.reshape(-1,1)\n",
        "\n",
        "        obs = next_obs\n",
        "      \n",
        "      print('roll_out')\n",
        "\n",
        "\n",
        "      with torch.no_grad():\n",
        "        # Calculate returns to go\n",
        "        returns_batch[self.config['max_timesteps']-1] = torch.where(done_batch[self.config['max_timesteps']-1]==0,\n",
        "                                                                    reward_batch[self.config['max_timesteps']-1] + self.config['gamma']*self.model.get_value(next_obs_batch[self.config['max_timesteps']-1])\n",
        "                                                                    ,torch.tensor(0.0))  # torch.no_grad?\n",
        "\n",
        "        print('after where')\n",
        "        # Calculate Advantage: \n",
        "        for t in range(self.config['max_timesteps']-2, -1, -1):\n",
        "          returns_batch[t] = torch.where(done_batch[t]==0, returns_batch[t+1]*self.config['gamma'] + reward_batch[t],torch.tensor(0.0))\n",
        "          advantage_batch[t] = returns_batch[t] - self.model.get_value(obs_batch[t])  # torch.no_grad?\n",
        "\n",
        "        # Reverse the whole batch?? \n",
        "        returns_batch = torch.flip(returns_batch,dims=[0])\n",
        "        print('adv')\n",
        "\n",
        "\n",
        "      # Optimization:\n",
        "      for k in range(self.config['num_epochs']):\n",
        "        # Create some mini-batches and update TODO ****\n",
        "\n",
        "          print('opt', flush=True)\n",
        "          obs_batch  = obs_batch.reshape(-1,self.envs.observation_space.shape[0])\n",
        "          action_batch = action_batch.reshape(-1, self.envs.action_space.shape[0])\n",
        "          reward_batch = reward_batch.reshape(-1,1)\n",
        "          done_batch = done_batch.reshape(-1,1)\n",
        "          next_obs_batch = next_obs_batch.reshape(-1,self.envs.observation_space.shape[0])\n",
        "          ratio_batch = ratio_batch.reshape(-1,1)\n",
        "          advantage_batch = advantage_batch.reshape(-1,1)\n",
        "          returns_batch = returns_batch.reshape(-1,1)\n",
        "          log_prob_batch = log_prob_batch.reshape(-1,1).detach()  # <--- notice detach\n",
        "          print('opt2', flush=True)\n",
        "\n",
        "          sample = torch.randint(0,self.config['num_workers'] * self.config['max_timesteps'],(64,))  # is this the right way to train the epochs? whole epochs maybe??\n",
        "\n",
        "          _,new_log_probs = self.model.get_action(obs_batch[sample],action_batch[sample])   \n",
        "          ratio = torch.exp(new_log_probs - log_prob_batch[sample]) \n",
        "          print('opt3', flush=True)\n",
        "          \n",
        "          print(advantage_batch[sample].requires_grad)  # showing up as False... \n",
        "          obj = ratio*advantage_batch[sample].detach()\n",
        "          clipped_obj = torch.clamp(ratio,1-self.config['epsilon'],1+self.config['epsilon'])*advantage_batch[sample].detach()  # missing *A? \n",
        "          loss = torch.mean(-torch.min(obj,clipped_obj) + advantage_batch[sample]**2)\n",
        "          print(loss, flush=True)\n",
        "          print('opt4', flush=True)\n",
        "          \n",
        "          self.optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kZkpTDFuK8Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppo = PPO(config)\n",
        "ppo.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gRjbZT_irnz",
        "outputId": "18d70a8f-be8e-4f03-e841-9e336d46a466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "roll_out\n",
            "after where\n",
            "adv\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(1601.2308, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(1940.5323, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(1680.2927, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(1879.4427, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(1804.8458, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(1655.1281, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(1600.9873, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(1715.5704, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(1546.1631, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(1337.1998, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "batch\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "roll_out\n",
            "after where\n",
            "adv\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(757.8370, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(784.7451, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(2890.1890, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(1743.2325, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(735.2930, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(951.5944, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(673.6531, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(771.5773, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(961.0862, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(674.0278, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "batch\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "roll_out\n",
            "after where\n",
            "adv\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(23094.6211, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(23175.2344, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(25773.4004, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(25965.2363, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(22374.6855, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(22094.8320, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(24271.3340, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(24649.2148, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(21852.8594, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(21874.7832, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "batch\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "roll_out\n",
            "after where\n",
            "adv\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(101573.4141, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(92974.1875, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(86638.0703, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(103954.4922, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(63875.5000, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(86059.5312, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(86527.7891, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(110570.3281, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(73971.0938, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(71868.8125, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "batch\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "roll_out\n",
            "after where\n",
            "adv\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(227927.8125, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(183816.3438, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(239219.5938, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(178235.9062, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(230326.2188, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(250622.7500, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(211084.5156, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(220339.6562, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(242218.9375, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(232920.7344, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "batch\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "roll_out\n",
            "after where\n",
            "adv\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(221383.3594, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(187758.9688, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(177577.6562, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(159122.5781, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(131834.2812, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(178896.1250, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(157968.3438, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(184921.2812, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(200655.4844, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(168730.9062, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "batch\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "roll_out\n",
            "after where\n",
            "adv\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(235654.3125, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(278807.9062, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(285462.3438, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(232866.7969, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(205490.7188, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(283048.7500, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(280506.6875, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(227773.5156, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(272686.6875, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(225402.2344, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "batch\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "model\n",
            "env\n",
            "gather\n",
            "roll_out\n",
            "after where\n",
            "adv\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(222375.1406, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(270209.1562, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(218644.5000, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(224577.2656, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(244697.0469, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(223744.5156, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(216268.2188, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(240682.1406, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(219224.0625, grad_fn=<MeanBackward0>)\n",
            "opt4\n",
            "opt\n",
            "opt2\n",
            "opt3\n",
            "True\n",
            "tensor(227588.9062, grad_fn=<MeanBackward0>)\n",
            "opt4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X3lFMvm-iwjj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}