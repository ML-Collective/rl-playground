**Resources found used during implementation sessions:**

* [This](https://www.youtube.com/watch?v=5P7I-xPq8u8&t=952s) is a video shared on the basics of PPO
* [This one](https://math.stackexchange.com/questions/3108216/change-of-variables-apply-tanh-to-the-gaussian-samples) explains the use of the TANH as the activation function on the Feed Forward
* [This](https://github.com/nikhilbarhate99/PPO-PyTorch/blob/master/PPO_colab.ipynb) is an implementation that we referred to for how to code the multivariatenormal policy



